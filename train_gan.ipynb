{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L8zv_cL8srYZ"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import random\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "from gaussian_noise import GaussianNoise\n",
    "from psnr import psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yqg-p9ggsqss",
    "outputId": "3b9efb33-1a4a-422a-9136-3d43117a1cde"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "77zQNwXNsaH3",
    "outputId": "eca7e265-d59e-41f3-e351-fe7cf46ab326"
   },
   "outputs": [],
   "source": [
    "img_size = 128\n",
    "totensor = transforms.ToTensor()\n",
    "resize = transforms.Resize((img_size, img_size))\n",
    "grayscale = transforms.Grayscale(num_output_channels=1)\n",
    "\n",
    "PYTORCH_TRANSFORM = transforms.Compose([grayscale,\n",
    "                                  resize,\n",
    "                                  totensor\n",
    "                                 ])\n",
    "gaussiannoise = GaussianNoise()\n",
    "\n",
    "def conv_down(in_ch, out_ch):\n",
    "    layer = nn.Conv2d(in_ch, out_ch, kernel_size=4, padding=1, stride=2)\n",
    "    return layer\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch=32):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.out_ch = out_ch\n",
    "        self.block = nn.Sequential(\n",
    "            conv_down(in_ch, out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            conv_down(out_ch, out_ch*2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            conv_down(out_ch*2, out_ch*4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            conv_down(out_ch*4, out_ch*8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            conv_down(out_ch*8, out_ch*8),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(out_ch*8*8*8, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        out = torch.sigmoid(self.linear(out.view(-1,self.out_ch*8*8*8)))\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, downsample=False):\n",
    "        super(ConvBlock, self).__init__()\n",
    "\n",
    "        self.block = nn.Sequential(nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace=True))\n",
    "        self.downsample = downsample\n",
    "\n",
    "        if self.downsample:\n",
    "            self.down_layer = conv_down(out_ch, out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        if self.downsample:\n",
    "            out_down = self.down_layer(out)\n",
    "            return out_down, out\n",
    "        return out\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(UpBlock, self).__init__()\n",
    "\n",
    "        self.up = nn.ConvTranspose2d(in_ch, out_ch, kernel_size=2, stride=2)\n",
    "        self.conv = ConvBlock(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x, upass):\n",
    "        upsampled = self.up(x)\n",
    "        combined = torch.cat((upsampled, upass), 1)\n",
    "        out = self.conv(combined)\n",
    "\n",
    "        return out\n",
    "\n",
    "class DeNoiser(nn.Module):\n",
    "    def __init__(self, in_ch, frames=32, depth=2):\n",
    "        super(DeNoiser, self).__init__()\n",
    "\n",
    "        self.depth = depth\n",
    "        self.collapse = nn.ModuleList()\n",
    "        prev_channels = in_ch\n",
    "\n",
    "        for i in range(depth):\n",
    "            downsample = True if (i+1) < depth else False\n",
    "            self.collapse.append(ConvBlock(prev_channels, frames*(2**i), downsample))\n",
    "            prev_channels = frames * (2**i)\n",
    "\n",
    "        self.restore = nn.ModuleList()\n",
    "        for i in reversed(range(depth - 1)):\n",
    "            self.restore.append(UpBlock(prev_channels, frames*(2**i)))\n",
    "            prev_channels = frames * (2**i)\n",
    "\n",
    "        self.final_conv = nn.Conv2d(prev_channels, in_ch, kernel_size=3, padding=1, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass_forward = []\n",
    "        for i, block in enumerate(self.collapse):\n",
    "            if (i + 1) < self.depth:\n",
    "                x, x_up = block(x)\n",
    "                pass_forward.append(x_up)\n",
    "            else:\n",
    "                x = block(x)\n",
    "\n",
    "        for i, block in enumerate(self.restore):\n",
    "            x = block(x, pass_forward[-i-1])\n",
    "\n",
    "        out = torch.sigmoid(self.final_conv(x))\n",
    "        return out\n",
    "            \n",
    "def discriminator_step(imgs, noisy, discriminator, disc_opt):\n",
    "    real = discriminator(imgs)\n",
    "    fake = discriminator(noisy)\n",
    "\n",
    "    real_loss = F.binary_cross_entropy(real, torch.zeros_like(real))\n",
    "    fake_loss = F.binary_cross_entropy(fake, torch.ones_like(fake))\n",
    "\n",
    "    loss = real_loss + fake_loss\n",
    "\n",
    "    disc_opt.zero_grad()\n",
    "    loss.backward()\n",
    "    disc_opt.step()\n",
    "\n",
    "    return real_loss, fake_loss\n",
    "\n",
    "def training_loop(n_epochs, optimizer, disc_opt, model, discriminator,\n",
    "                  loss_func, train_loader, pretrain_epoch=3, alpha=0.001):\n",
    "    for epoch in range(1, pretrain_epoch+1):\n",
    "        real_losses = 0\n",
    "        fake_losses = 0\n",
    "        #for imgs, labels in tqdm(train_loader):\n",
    "        #    noise_gen = GaussianNoise(var=random.uniform(0.005,0.05))\n",
    "        #    noisy = noise_gen(imgs).cuda()\n",
    "        #    imgs, labels = imgs.cuda(), labels.cuda()\n",
    "\n",
    "        #    real_loss, fake_loss = discriminator_step(imgs, noisy,\n",
    "        #                                              discriminator, disc_opt)\n",
    "\n",
    "        #    real_losses += real_loss.item()\n",
    "        #    fake_losses += fake_loss.item()\n",
    "\n",
    "        #with open(\"unet_loss.txt\", \"a\") as resfile:\n",
    "        #    print(\"Epoch {}: Training loss {} {}\".format(\n",
    "        #        epoch, float(real_losses), float(fake_losses)), file=resfile)\n",
    "    noise_gen = GaussianNoise()\n",
    "    for epoch in tqdm(range(1, n_epochs + 1)):\n",
    "        recon_losses = 0\n",
    "        disc_losses = 0\n",
    "        real_losses = 0\n",
    "        fake_losses = 0\n",
    "        for imgs, labels in train_loader:\n",
    "            noisy = noise_gen(imgs).float().cuda()\n",
    "            imgs, labels = imgs.cuda(), labels.cuda()\n",
    "\n",
    "            outputs = model(noisy)\n",
    "            disc_out = discriminator(outputs)\n",
    "\n",
    "            recon_loss = F.mse_loss(outputs, imgs)\n",
    "            disc_loss = F.binary_cross_entropy(disc_out,\n",
    "                                               torch.zeros_like(disc_out))\n",
    "\n",
    "            loss = recon_loss + alpha * disc_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            noisy = noise_gen(imgs.cpu()).float().cuda()\n",
    "            outputs = model(noisy)            \n",
    "            real_loss, fake_loss = discriminator_step(imgs, outputs.detach(),\n",
    "                                                      discriminator, disc_opt)\n",
    "\n",
    "            recon_losses += recon_loss.item()\n",
    "            disc_losses += disc_loss.item()\n",
    "            real_losses += real_loss.item()\n",
    "            fake_losses += fake_loss.item()\n",
    "\n",
    "        save_image(noisy, str(epoch) + \"_noisy.png\")\n",
    "        save_image(imgs, str(epoch) + \"_real.png\")\n",
    "        save_image(outputs, str(epoch) + \"_recon.png\")\n",
    "\n",
    "        with open(\"unet_loss.txt\", \"a\") as resfile:\n",
    "            print(\"Epoch {}: Training loss {} {} {} {}\".format(\n",
    "                epoch, float(recon_losses), float(disc_losses),\n",
    "                float(real_losses), float(fake_losses)), file=resfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-8CNC-uUKrih"
   },
   "outputs": [],
   "source": [
    "imgs = ImageFolder(\"train\", PYTORCH_TRANSFORM)\n",
    "full = torch.utils.data.DataLoader(imgs, batch_size=128)\n",
    "\n",
    "model = nn.DataParallel(DeNoiser(1)).cuda()\n",
    "model.load_state_dict(torch.load(\"unet.pt\"))\n",
    "model.eval()\n",
    "model = model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_func = nn.NLLLoss().cuda().cuda()\n",
    "\n",
    "discriminator = nn.DataParallel(Discriminator(1)).cuda()\n",
    "disc_opt = optim.Adam(discriminator.parameters(), lr=1e-4)\n",
    "\n",
    "training_loop(10, optimizer, disc_opt, model, discriminator, loss_func, full)\n",
    "\n",
    "torch.save(model.state_dict(), \"gan.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rAW0Z1U9KpqN",
    "outputId": "35b36e87-5009-4f2d-a2d3-e4790ec2ad62"
   },
   "outputs": [],
   "source": [
    "model = nn.DataParallel(DeNoiser(1)).cuda()\n",
    "model.load_state_dict(torch.load(\"gan.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CybywkEutl_i"
   },
   "outputs": [],
   "source": [
    "test_clean = torch.load(\"test/test_clean.pt\")\n",
    "test_noisy_010 = torch.load(\"test/test_noisy_var_0.010.pt\")\n",
    "test_noisy_025 = torch.load(\"test/test_noisy_var_0.025.pt\")\n",
    "test_noisy_050 = torch.load(\"test/test_noisy_var_0.050.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MkhK9l6ytorr",
    "outputId": "cafca78b-5886-4235-c136-181f12e747be"
   },
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    test_pred_010 = model(test_noisy_010.float()).cpu().float()\n",
    "    psnr_nn_010 = psnr(test_clean, test_pred_010)\n",
    "\n",
    "torch.save(test_pred_010, \"gan_autoencoder_denoised/var_010.pt\")\n",
    "\n",
    "print(\"PSNR for GAN: {:f} for noise var=0.010\".format(psnr_nn_010))\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_pred_025 = model(test_noisy_025.float()).cpu().float()\n",
    "    psnr_nn_025 = psnr(test_clean, test_pred_025)\n",
    "\n",
    "torch.save(test_pred_025, \"gan_autoencoder_denoised/var_025.pt\")\n",
    "\n",
    "print(\"PSNR for GAN: {:f} for noise var=0.025\".format(psnr_nn_025))\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_pred_050 = model(test_noisy_050.float()).cpu().float()\n",
    "    psnr_nn_050 = psnr(test_clean, test_pred_050)\n",
    "\n",
    "torch.save(test_pred_050, \"gan_autoencoder_denoised/var_050.pt\")\n",
    "\n",
    "print(\"PSNR for GAN: {:f} for noise var=0.050\".format(psnr_nn_050))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "id": "aAc5ky8oqZn_",
    "outputId": "a188f3f3-9bbc-41cf-a599-316ce10515ac"
   },
   "outputs": [],
   "source": [
    "test_img = test_noisy_010[0].squeeze().cpu().numpy()\n",
    "nn_denoised_img = test_pred_010[0].squeeze().cpu().detach().numpy()\n",
    "gt_img = test_clean[0].squeeze().cpu().numpy()\n",
    "\n",
    "fig, (ax1, ax2, ax4) = plt.subplots(1,3, figsize=(10,30))\n",
    "ax1.imshow(test_img, cmap='gray')\n",
    "ax1.set_title(\"noisy img\")\n",
    "ax2.imshow(nn_denoised_img, cmap='gray')\n",
    "ax2.set_title(\"GAN denoised img\")\n",
    "ax4.imshow(gt_img, cmap='gray')\n",
    "ax4.set_title(\"ground truth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "id": "SxV-tllnq8bW",
    "outputId": "1304719b-bf83-451b-bec8-5c0e0674c2f6"
   },
   "outputs": [],
   "source": [
    "test_img = test_noisy_025[0].squeeze().cpu().numpy()\n",
    "nn_denoised_img = test_pred_025[0].squeeze().cpu().detach().numpy()\n",
    "gt_img = test_clean[0].squeeze().cpu().numpy()\n",
    "\n",
    "fig, (ax1, ax2, ax4) = plt.subplots(1,3, figsize=(10,30))\n",
    "ax1.imshow(test_img, cmap='gray')\n",
    "ax1.set_title(\"noisy img\")\n",
    "ax2.imshow(nn_denoised_img, cmap='gray')\n",
    "ax2.set_title(\"GAN denoised img\")\n",
    "ax4.imshow(gt_img, cmap='gray')\n",
    "ax4.set_title(\"ground truth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "id": "dJzGRqeOrBTF",
    "outputId": "6e465f36-1548-4c80-e320-dc870c5417f3"
   },
   "outputs": [],
   "source": [
    "test_img = test_noisy_050[0].squeeze().cpu().numpy()\n",
    "nn_denoised_img = test_pred_050[0].squeeze().cpu().detach().numpy()\n",
    "gt_img = test_clean[0].squeeze().cpu().numpy()\n",
    "\n",
    "fig, (ax1, ax2, ax4) = plt.subplots(1,3, figsize=(10,30))\n",
    "ax1.imshow(test_img, cmap='gray')\n",
    "ax1.set_title(\"noisy img\")\n",
    "ax2.imshow(nn_denoised_img, cmap='gray')\n",
    "ax2.set_title(\"GAN denoised img\")\n",
    "ax4.imshow(gt_img, cmap='gray')\n",
    "ax4.set_title(\"ground truth\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "gan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
