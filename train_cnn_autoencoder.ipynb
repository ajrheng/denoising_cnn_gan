{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AJQaOyGUe-MD"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from gaussian_noise import GaussianNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eNF9VBn0e-MI",
    "outputId": "87ce3181-5930-4a80-b8d8-2ee9b43e9804"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MJuAIyJRe-ML"
   },
   "outputs": [],
   "source": [
    "gaussiannoise = GaussianNoise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UxPfaQy2e-ML"
   },
   "outputs": [],
   "source": [
    "img_size = 128\n",
    "totensor = transforms.ToTensor()\n",
    "resize = transforms.Resize((img_size, img_size))\n",
    "grayscale = transforms.Grayscale(num_output_channels=1)\n",
    "transforms_ = transforms.Compose([totensor,\n",
    "                                grayscale,\n",
    "                                resize])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(\"train\", transform=transforms_)\n",
    "train_data_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YH0_VbrRSmxP"
   },
   "outputs": [],
   "source": [
    "test_clean = torch.load(\"test/test_clean.pt\")\n",
    "test_noisy_005 = torch.load(\"test/test_noisy_var_0.005.pt\")\n",
    "test_noisy_010 = torch.load(\"test/test_noisy_var_0.010.pt\")\n",
    "test_noisy_025 = torch.load(\"test/test_noisy_var_0.025.pt\")\n",
    "test_noisy_050 = torch.load(\"test/test_noisy_var_0.050.pt\")\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(test_noisy_010, test_clean) ## while training, test on var=0.010 dataset\n",
    "test_data_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M7i4pMiAe-MP"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class cnn_autoencoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(cnn_autoencoder,self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, 4, padding=1, stride=2) # [1, 128, 128] -> [64, 64, 64]\n",
    "        self.conv1_bn = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 128, 4, padding=1, stride=2) # [64, 64, 64] -> [128, 32, 32]\n",
    "        self.conv2_bn = nn.BatchNorm2d(128)\n",
    "  \n",
    "        self.conv3 = nn.Conv2d(128, 256, 4, padding=1, stride=2) # [128, 32, 32] -> [256, 16, 16]\n",
    "        self.conv3_bn = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.conv4 = nn.ConvTranspose2d(256, 128, 4, padding=1, stride=2) # [256, 16, 16] -> [128, 32, 32]\n",
    "        self.conv4_bn = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv5 = nn.ConvTranspose2d(128, 64, 4, padding=1, stride=2) # [128, 32, 32] -> [64, 64, 64]\n",
    "        self.conv5_bn = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv6 = nn.ConvTranspose2d(64, 1, 4, padding=1, stride=2) # [64, 64, 64] -> [1, 128, 128]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1_bn(F.relu(self.conv1(x)))\n",
    "        x = self.conv2_bn(F.relu(self.conv2(x)))\n",
    "        x = self.conv3_bn(F.relu(self.conv3(x)))\n",
    "        x = self.conv4_bn(F.relu(self.conv4(x)))\n",
    "        x = self.conv5_bn(F.relu(self.conv5(x)))\n",
    "        x = torch.sigmoid(self.conv6(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AEMek9MNe-MP",
    "outputId": "a4933e9f-8476-43db-d185-1406d9a41f8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cnn_autoencoder(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (conv1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (conv2_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (conv3_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (conv4_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (conv5_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv6): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = cnn_autoencoder()\n",
    "net.to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bnypJ6gZe-MP",
    "outputId": "5e874d86-24bc-4afb-f515-a4ce42dcceea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train loss: 0.611233, test loss 0.578793\n",
      "Epoch: 1, train loss: 0.560013, test loss 0.560193\n",
      "Epoch: 2, train loss: 0.557247, test loss 0.558593\n",
      "Epoch: 3, train loss: 0.555441, test loss 0.556569\n",
      "Epoch: 4, train loss: 0.554043, test loss 0.556235\n",
      "Epoch: 5, train loss: 0.553540, test loss 0.555194\n",
      "Epoch: 6, train loss: 0.553393, test loss 0.555506\n",
      "Epoch: 7, train loss: 0.552449, test loss 0.554327\n",
      "Epoch: 8, train loss: 0.552390, test loss 0.558210\n",
      "Epoch: 9, train loss: 0.552658, test loss 0.555041\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(10):\n",
    "    \n",
    "    running_train_loss = 0\n",
    "    counter = 0\n",
    "\n",
    "    for train_batch in train_data_loader:\n",
    "        gt = train_batch[0].to(device)\n",
    "        noisy = gaussiannoise(train_batch[0]).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = net(noisy.float())\n",
    "        train_loss = criterion(output, gt.float())\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        running_train_loss += train_loss.item()\n",
    "        counter += 1\n",
    "        \n",
    "    net.eval()\n",
    "    test_loss = []\n",
    "    for test_batch in test_data_loader:\n",
    "        test_noisy = test_batch[0].to(device)\n",
    "        test_clean = test_batch[1].to(device)\n",
    "        test_output = net(test_noisy.float())\n",
    "        test_loss_val = criterion(test_output, test_clean)\n",
    "        test_loss.append(test_loss_val.item())\n",
    "    net.train()\n",
    "\n",
    "    print(\"Epoch: {:d}, train loss: {:f}, test loss {:f}\".format(epoch, running_train_loss/counter, np.mean(test_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y7a1X5Nt9r8A"
   },
   "outputs": [],
   "source": [
    "# torch.save(net.state_dict(), \"cnn_autoencoder_pathology.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HVb994v87rkp"
   },
   "outputs": [],
   "source": [
    "test_pred_010 = net(test_noisy_010.float()).detach().cpu().float()\n",
    "psnr_nn_010 = psnr(test_clean, test_pred_010)\n",
    "\n",
    "fastNI_010 = torch.empty((0, 1, img_size, img_size))\n",
    "\n",
    "for i in range(len(test_noisy_010)):\n",
    "    noisy_img = test_noisy_010[i]\n",
    "    noisy_img = (noisy_img.cpu().numpy().squeeze() * 255).astype(np.uint8)\n",
    "    denoised = cv.fastNlMeansDenoising(noisy_img, None, 50, 7, 21)\n",
    "    denoised = denoised[:,:,np.newaxis]\n",
    "    denoised = totensor(denoised)\n",
    "    fastNI_010 = torch.cat((fastNI_010, denoised.unsqueeze(0)), dim=0)\n",
    "\n",
    "psnr_opencv_010 = psnr(test_clean, fastNI_010)\n",
    "\n",
    "torch.save(test_pred_010, \"cnn_autoencoder_denoised/var_010.pt\")\n",
    "torch.save(fastNI_010, \"classical_denoised/var_010.pt\")\n",
    "\n",
    "\n",
    "print(\"PSNR for CNN: {:f} vs OpenCV: {:f} for noise var=0.010\".format(psnr_nn_010, psnr_opencv_010))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = test_noisy_010[0].squeeze().cpu().numpy()\n",
    "nn_denoised_img = test_pred_010[0].squeeze().cpu().detach().numpy()\n",
    "ni_denoised_img = fastNI_010[0].squeeze().numpy()\n",
    "gt_img = test_clean[0].squeeze().cpu().numpy()\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1,4, figsize=(10,40))\n",
    "ax1.imshow(test_img, cmap='gray')\n",
    "ax1.set_title(\"noisy img\")\n",
    "ax2.imshow(nn_denoised_img, cmap='gray')\n",
    "ax2.set_title(\"NN denoised img\")\n",
    "ax3.imshow(ni_denoised_img, cmap='gray')\n",
    "ax3.set_title(\"Classically denoised img\")\n",
    "ax4.imshow(gt_img, cmap='gray')\n",
    "ax4.set_title(\"ground truth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_025 = net(test_noisy_025.float()).detach().cpu().float()\n",
    "psnr_nn_025 = psnr(test_clean, test_pred_025)\n",
    "\n",
    "fastNI_025 = torch.empty((0, 1, img_size, img_size))\n",
    "\n",
    "for i in range(len(test_noisy_025)):\n",
    "    noisy_img = test_noisy_025[i]\n",
    "    noisy_img = (noisy_img.cpu().numpy().squeeze() * 255).astype(np.uint8)\n",
    "    denoised = cv.fastNlMeansDenoising(noisy_img, None, 50, 7, 21)\n",
    "    denoised = denoised[:,:,np.newaxis]\n",
    "    denoised = totensor(denoised)\n",
    "    fastNI_025 = torch.cat((fastNI_025, denoised.unsqueeze(0)), dim=0)\n",
    "\n",
    "psnr_opencv_025 = psnr(test_clean, fastNI_025)\n",
    "\n",
    "torch.save(test_pred_025, \"cnn_autoencoder_denoised/var_025.pt\")\n",
    "torch.save(fastNI_025, \"classical_denoised/var_025.pt\")\n",
    "\n",
    "print(\"PSNR for CNN: {:f} vs OpenCV: {:f} for noise var=0.025\".format(psnr_nn_025, psnr_opencv_025))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = test_noisy_025[0].squeeze().cpu().numpy()\n",
    "nn_denoised_img = test_pred_025[0].squeeze().cpu().detach().numpy()\n",
    "ni_denoised_img = fastNI_025[0].squeeze().numpy()\n",
    "gt_img = test_clean[0].squeeze().cpu().numpy()\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1,4, figsize=(10,40))\n",
    "ax1.imshow(test_img, cmap='gray')\n",
    "ax1.set_title(\"noisy img\")\n",
    "ax2.imshow(nn_denoised_img, cmap='gray')\n",
    "ax2.set_title(\"NN denoised img\")\n",
    "ax3.imshow(ni_denoised_img, cmap='gray')\n",
    "ax3.set_title(\"Classically denoised img\")\n",
    "ax4.imshow(gt_img, cmap='gray')\n",
    "ax4.set_title(\"ground truth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_050 = net(test_noisy_050.float()).detach().cpu().float()\n",
    "psnr_nn_050 = psnr(test_clean, test_pred_050)\n",
    "\n",
    "fastNI_050 = torch.empty((0, 1, img_size, img_size))\n",
    "\n",
    "for i in range(len(test_noisy_050)):\n",
    "    noisy_img = test_noisy_050[i]\n",
    "    noisy_img = (noisy_img.cpu().numpy().squeeze() * 255).astype(np.uint8)\n",
    "    denoised = cv.fastNlMeansDenoising(noisy_img, None, 50, 7, 21)\n",
    "    denoised = denoised[:,:,np.newaxis]\n",
    "    denoised = totensor(denoised)\n",
    "    fastNI_050 = torch.cat((fastNI_050, denoised.unsqueeze(0)), dim=0)\n",
    "\n",
    "psnr_opencv_050 = psnr(test_clean, fastNI_050)\n",
    "\n",
    "torch.save(test_pred_050, \"cnn_autoencoder_denoised/var_050.pt\")\n",
    "torch.save(fastNI_050, \"classical_denoised/var_050.pt\")\n",
    "\n",
    "print(\"PSNR for CNN: {:f} vs OpenCV: {:f} for noise var=0.050\".format(psnr_nn_050, psnr_opencv_050))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = test_noisy_050[0].squeeze().cpu().numpy()\n",
    "nn_denoised_img = test_pred_050[0].squeeze().cpu().detach().numpy()\n",
    "ni_denoised_img = fastNI_050[0].squeeze().numpy()\n",
    "gt_img = test_clean[0].squeeze().cpu().numpy()\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1,4, figsize=(10,40))\n",
    "ax1.imshow(test_img, cmap='gray')\n",
    "ax1.set_title(\"noisy img\")\n",
    "ax2.imshow(nn_denoised_img, cmap='gray')\n",
    "ax2.set_title(\"NN denoised img\")\n",
    "ax3.imshow(ni_denoised_img, cmap='gray')\n",
    "ax3.set_title(\"Classically denoised img\")\n",
    "ax4.imshow(gt_img, cmap='gray')\n",
    "ax4.set_title(\"ground truth\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train-cnn-autoencoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
